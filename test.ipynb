{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from src.models.diffusion import TextDiffusionModel\n",
    "import torch.nn.functional as F\n",
    "from src.utils import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextDiffusionModel.load_from_checkpoint(\"logs/lightning_logs/bxspp7rv/checkpoints/epoch=91-step=38916.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = model.diffusion.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb2indices(output, emb_layer):\n",
    "    # output is size: [batch, sequence, emb_length], emb_layer is size: [num_tokens, emb_length]\n",
    "    emb_weights = emb_layer.weight\n",
    "    batch_size, embedding_dim, token_num = output.size()\n",
    "    output = output.view(batch_size, token_num, embedding_dim)\n",
    "    # get indices from embeddings:\n",
    "    emb_size = output.size(0), output.size(1), -1, -1\n",
    "    out_size = -1, -1, emb_weights.size(0), -1\n",
    "    out_indices = torch.argmin(\n",
    "        torch.abs(output.unsqueeze(2).expand(out_size) - emb_weights.unsqueeze(0).unsqueeze(0).expand(emb_size)).sum(dim=3),\n",
    "        dim=2,\n",
    "    )\n",
    "    return out_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/kiltertextdiffuse/raw/all_climbs.csv\")\n",
    "class Tokenizer:\n",
    "    def __init__(self, df: pd.DataFrame, max_len: int = 64):\n",
    "        self.df = df\n",
    "        self.max_len = max_len\n",
    "        self.token_map = self._get_token_map()\n",
    "        self.decode_map = {v: k for k, v in self.token_map.items()}\n",
    "\n",
    "    @staticmethod\n",
    "    def split_tokens(frames: str) -> list[str]:\n",
    "        res = []\n",
    "        for pair in frames.split(\"p\")[1:]:\n",
    "            hold, color = pair.split(\"r\")\n",
    "            res += [f\"p{hold}\", f\"r{color}\"]\n",
    "        return res\n",
    "\n",
    "    def __call__(self, frames: str) -> torch.Tensor:\n",
    "        split = self.split_tokens(frames)\n",
    "        n = len(split)\n",
    "        if n >= self.max_len:\n",
    "            split = split[: self.max_len]\n",
    "        else:\n",
    "            split += [\"[PAD]\"] * (self.max_len - n)\n",
    "        return torch.tensor([self.token_map[x] for x in split], dtype=torch.long)\n",
    "\n",
    "    def decode(self, samples: list[list[int]]) -> list[str]:\n",
    "        climbs = []\n",
    "        for climb in samples:\n",
    "            climb_str = \"\"\n",
    "            for hold in climb:\n",
    "                climb_str += self.decode_map[hold]\n",
    "            climbs.append(climb_str)\n",
    "        return climbs\n",
    "\n",
    "    def _get_token_map(self) -> dict[str, int]:\n",
    "        tokens = set()\n",
    "        for name, row in self.df.iterrows():\n",
    "            tokens.update(self.split_tokens(row[\"frames\"]))\n",
    "        token_map = {token: idx + 1 for idx, token in enumerate(tokens)}\n",
    "        token_map[\"[PAD]\"] = 0\n",
    "        return token_map\n",
    "T = Tokenizer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE()\n",
    "x = tsne.fit_transform(model.embedding.weight.data[:532].cpu())\n",
    "df = pd.DataFrame(data=x, columns=[\"x\", \"y\"])\n",
    "df['token'] = T.token_map.keys()\n",
    "import plotly.express as px\n",
    "df['type'] = \"hold\"\n",
    "df[df['token'].str.contains(\"r\")] = \"color\"\n",
    "px.scatter(df, x=\"x\", y=\"y\", hover_name=\"token\", color=\"type\", opacity=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = emb2indices(samples, model.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [x.strip(\"[PAD]\") for x in T.decode(t.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
